{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set size: (1460, 81)\n",
      "Test set size: (1459, 80)\n",
      "START data processing 2019-05-08 22:01:30.678161\n",
      "剔除训练数据中的极端值后，将其特征矩阵和测试数据中的特征矩阵合并，维度为: (2917, 79)\n",
      "删除了3个特征，又融合创建了10个新特征，处理之后的特征矩阵维度为: (2917, 86)\n",
      "使用get_dummies()方法“投影”特征矩阵，即分解出更多特征，得到更多列。投影后的特征矩阵维度为: (2917, 333)\n",
      "删除了3个特征，又融合创建了10个新特征，处理之后的特征矩阵维度为: X (1458, 333) y (1458,) X_sub (1459, 333)\n",
      "删除极端值及过拟合列后，训练数据特征矩阵的维数为，特征： X (1453, 332) 对应于特征的对数变换后的房价y (1453,) 测试数据的特征矩阵（它应该在行、列上未被删减）X_sub (1459, 332)\n",
      "特征处理已经完成。开始对训练数据进行机器学习 2019-05-08 22:01:32.050256\n",
      "进行交叉验证，计算不同模型的得分TEST score on CV\n",
      "二范数rideg岭回归模型的得分: 0.1013 (0.0140)\n",
      " 2019-05-08 22:01:50.042117\n",
      "一范数LASSO收缩模型的得分: 0.1002 (0.0142)\n",
      " 2019-05-08 22:02:04.843228\n",
      "elastic net弹性网络模型的得分: 0.1002 (0.0143)\n",
      " 2019-05-08 22:02:58.184948\n",
      "SVR支持向量机模型的得分: 0.1016 (0.0130)\n",
      " 2019-05-08 22:03:10.754065\n",
      "lightgbm轻梯度提升模型的得分: 0.1060 (0.0154)\n",
      " 2019-05-08 22:03:26.739822\n",
      "gbr梯度提升回归模型的得分: 0.1088 (0.0154)\n",
      " 2019-05-08 22:05:18.953855\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hjz/anaconda3/lib/python3.7/site-packages/xgboost/core.py:587: FutureWarning: Series.base is deprecated and will be removed in a future version\n",
      "  if getattr(data, 'base', None) is not None and \\\n",
      "/home/hjz/anaconda3/lib/python3.7/site-packages/xgboost/core.py:587: FutureWarning: Series.base is deprecated and will be removed in a future version\n",
      "  if getattr(data, 'base', None) is not None and \\\n",
      "/home/hjz/anaconda3/lib/python3.7/site-packages/xgboost/core.py:587: FutureWarning: Series.base is deprecated and will be removed in a future version\n",
      "  if getattr(data, 'base', None) is not None and \\\n",
      "/home/hjz/anaconda3/lib/python3.7/site-packages/xgboost/core.py:587: FutureWarning: Series.base is deprecated and will be removed in a future version\n",
      "  if getattr(data, 'base', None) is not None and \\\n",
      "/home/hjz/anaconda3/lib/python3.7/site-packages/xgboost/core.py:587: FutureWarning: Series.base is deprecated and will be removed in a future version\n",
      "  if getattr(data, 'base', None) is not None and \\\n",
      "/home/hjz/anaconda3/lib/python3.7/site-packages/xgboost/core.py:587: FutureWarning: Series.base is deprecated and will be removed in a future version\n",
      "  if getattr(data, 'base', None) is not None and \\\n",
      "/home/hjz/anaconda3/lib/python3.7/site-packages/xgboost/core.py:587: FutureWarning: Series.base is deprecated and will be removed in a future version\n",
      "  if getattr(data, 'base', None) is not None and \\\n",
      "/home/hjz/anaconda3/lib/python3.7/site-packages/xgboost/core.py:587: FutureWarning: Series.base is deprecated and will be removed in a future version\n",
      "  if getattr(data, 'base', None) is not None and \\\n",
      "/home/hjz/anaconda3/lib/python3.7/site-packages/xgboost/core.py:587: FutureWarning: Series.base is deprecated and will be removed in a future version\n",
      "  if getattr(data, 'base', None) is not None and \\\n",
      "/home/hjz/anaconda3/lib/python3.7/site-packages/xgboost/core.py:587: FutureWarning: Series.base is deprecated and will be removed in a future version\n",
      "  if getattr(data, 'base', None) is not None and \\\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "xgboost模型的得分: 0.1050 (0.0152)\n",
      " 2019-05-08 22:07:50.291984\n",
      "进行模型参数训练 START Fit\n",
      "2019-05-08 22:07:50.292801 对stack_gen集成器模型进行参数训练\n",
      "2019-05-08 22:11:35.105899 对elasticnet弹性网络模型进行参数训练\n",
      "2019-05-08 22:11:41.341497 对一范数lasso收缩模型进行参数训练\n",
      "2019-05-08 22:11:42.916515 对二范数ridge岭回归模型进行参数训练\n",
      "2019-05-08 22:11:44.808714 对svr支持向量机模型进行参数训练\n",
      "2019-05-08 22:11:46.258931 对GradientBoosting梯度提升模型进行参数训练\n",
      "2019-05-08 22:11:57.949312 对xgboost二阶梯度提升模型进行参数训练\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hjz/anaconda3/lib/python3.7/site-packages/xgboost/core.py:587: FutureWarning: Series.base is deprecated and will be removed in a future version\n",
      "  if getattr(data, 'base', None) is not None and \\\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-05-08 22:12:14.338930 对lightgbm轻梯度提升模型进行参数训练\n",
      "融合后的训练模型对原数据重构时的均方根对数误差RMSLE score on train data:\n",
      "0.05544006045470143\n",
      "使用测试集特征进行房价预测 Predict submission 2019-05-08 22:12:18.107952\n",
      "融合其他优秀模型的预测结果 Blend with Top Kernals submissions 2019-05-08 22:12:20.041445\n",
      "融合结果.csv文件输出成功 Save submission 2019-05-08 22:12:21.986459\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#导入计算模块，对模块大致功能注解：\n",
    "#numpy支持矩阵运算\n",
    "#pandas用来做数据清洗，像是python中的excel（支持将数据以.csv格式输出至本地）\n",
    "#sklearn用来进一步制作数据集（支持数据的导入和数据的导出），含有SVM支持向量机、DT决策树、KNN近邻、LR逻辑回归等封装好的模型，支持对数据进行交叉验证以调参。\n",
    "#mlxtend用来实现集成学习：bagging, boosting, stacking\n",
    "#lightgbm内有boosting tree（相比xgboost，改进了生成节点的方式）\n",
    "#xgboost内有boosting tree\n",
    "#os用来读取文件\n",
    "import numpy as np  # linear algebra\n",
    "import pandas as pd  #\n",
    "from datetime import datetime\n",
    "from scipy.stats import skew  # for some statistics\n",
    "from scipy.special import boxcox1p\n",
    "from scipy.stats import boxcox_normmax\n",
    "from sklearn.linear_model import ElasticNetCV, LassoCV, RidgeCV\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "from sklearn.model_selection import KFold, cross_val_score\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from mlxtend.regressor import StackingCVRegressor\n",
    "from xgboost import XGBRegressor\n",
    "from lightgbm import LGBMRegressor\n",
    "import os\n",
    "\n",
    "#######################################################数据导入和特征提取-【开始】################################################################################\n",
    "#显示当前编译器的Draft Environment下的文件；将文件夹下的对应名称csv文件储存为矩阵对象。\n",
    "\n",
    "train = pd.read_csv('train.csv')\n",
    "test = pd.read_csv('test.csv')\n",
    "\n",
    "#显示矩阵对象的维数，核查是否导入成功\n",
    "print(\"Train set size:\", train.shape)\n",
    "print(\"Test set size:\", test.shape)\n",
    "\n",
    "#记录运算开始的时间\n",
    "print('START data processing', datetime.now(), )\n",
    "\n",
    "#取出train矩阵（或者称之为“数据帧”dataframe）中title为'Id'的列，赋值给train_ID。所以train_ID是一维列向量了。test_ID类似。\n",
    "#train_ID和test_ID根本就没有使用，完全可以删除。\n",
    "#train_ID = train['Id']\n",
    "#test_ID = test['Id']\n",
    "\n",
    "##################删除训练集和测试集中的标签列-【开始】#################\n",
    "#将train矩阵中的'Id'列删除（原地删除，故将inplace设为true），因为原始数据中的数据索引和预测模型的构建没有关系。\n",
    "#test矩阵类似。\n",
    "train.drop(['Id'], axis=1, inplace=True)\n",
    "test.drop(['Id'], axis=1, inplace=True)\n",
    "##################删除训练集和测试集中的标签列-【结束】#################\n",
    "\n",
    "###############删除训练集中的极端值和进行数据index更新-【开始】#########\n",
    "#使用条件筛选操作，通过覆值的方式剔除原始数据train矩阵中的极端值（极端值也被称为outliers），帮助预防房价预测模型出现过拟合。剔除操作也可以视为前剪枝。\n",
    "train = train[train.GrLivArea < 4500]\n",
    "#由于删去了部分行，故此时train矩阵中的index列并不连续。使用reset_index命令，在固定非index数据的顺序的前提下（inplace=True），重新对index编号（drop=True）。\n",
    "train.reset_index(drop=True, inplace=True)\n",
    "###############删除训练集中的极端值和进行数据index更新-【结束】#########\n",
    "\n",
    "##########对预测目标数值进行对数变换和特征矩阵对象的创建-【开始】#######\n",
    "# log1p就是log(1+x)，用来对房价数据进行数据预处理，它的好处是转化后的数据更加服从高斯分布，有利于后续的分类结果。\n",
    "# 需要注意，最后需要将预测出的平滑数据还原，而还原过程就是log1p的逆运算expm1。\n",
    "train[\"SalePrice\"] = np.log1p(train[\"SalePrice\"])\n",
    "#单独取出训练数据中的房价列信息，存入y对象。\n",
    "#y = train.SalePrice.reset_index(drop=True) #.reset_index(drop=True)方法：在原有的索引列重置索引，不再另外添加新列。有必要使用reset_index吗？有必要的，不这样做y将有两套index，作为df的y将有两列。\n",
    "y = train['SalePrice'].reset_index(drop=True) #对上式的改写\n",
    "#沿着水平的方向寻找列名为'SalePrice'的列（们），把它们对应的列统统删掉。得到了单纯的特征矩阵，存入train_features对象中。\n",
    "train_features = train.drop(['SalePrice'], axis=1)\n",
    "#test本来就没有房价列，所以它本来就是单纯的特征矩阵。\n",
    "test_features = test\n",
    "##########对预测目标数值进行对数变换和特征矩阵对象的创建-【结束】#######\n",
    "\n",
    "##合并训练数据特征矩阵与测试数据特征矩阵，以便统一进行特征处理-【开始】##\n",
    "#将训练数据中的特征矩阵和测试数据中的特征矩阵合并（.concat[矩阵1,矩阵2]），并对合并后的矩阵index重新编号（.reset_index(drop=True)）。\n",
    "features = pd.concat([train_features, test_features]).reset_index(drop=True)\n",
    "#检查合并后的矩阵的维数，核查合并结果。\n",
    "print(\"剔除训练数据中的极端值后，将其特征矩阵和测试数据中的特征矩阵合并，维度为:\",features.shape)\n",
    "##合并训练数据特征矩阵与测试数据特征矩阵，以便统一进行特征处理-【结束】##\n",
    "#######################################################数据导入和特征提取-【结束】################################################################################\n",
    "\n",
    "##############################################################特征处理-【开始】###################################################################################\n",
    "#对于列名为'MSSubClass'、'YrSold'、'MoSold'的特征列，将列中的数据类型转化为string格式。\n",
    "features['MSSubClass'] = features['MSSubClass'].apply(str)\n",
    "features['YrSold'] = features['YrSold'].astype(str)\n",
    "features['MoSold'] = features['MoSold'].astype(str)\n",
    "\n",
    "###############################填充空值-【开始】##########################\n",
    "#按照以下各个特征列的实际情况，依次处理各个特征列中的空值（.fillna()方法）\n",
    "features['Functional'] = features['Functional'].fillna('Typ') #空值填充为str型数据'Typ'\n",
    "features['Electrical'] = features['Electrical'].fillna(\"SBrkr\") #空值填充为str型数据\"SBrkr\"\n",
    "features['KitchenQual'] = features['KitchenQual'].fillna(\"TA\") #空值填充为str型数据\"TA\"\n",
    "features[\"PoolQC\"] = features[\"PoolQC\"].fillna(\"None\") #空值填充为str型数据\"None\"\n",
    "\n",
    "#对于列名为'Exterior1st'、'Exterior2nd'、'SaleType'的特征列，使用列中的众数填充空值。\n",
    "#\t1.先查找数据列中的众数：使用df.mode()[]方法\n",
    "#\t  解释：df.mode(0或1,0表示对列查找，1表示对行查找)[需要查找众数的df列的index（就是df中的第几列）]，将返回数据列中的众数\n",
    "#\t2.使用.fillna()方法进行填充\n",
    "features['Exterior1st'] = features['Exterior1st'].fillna(features['Exterior1st'].mode()[0]) \n",
    "features['Exterior2nd'] = features['Exterior2nd'].fillna(features['Exterior2nd'].mode()[0])\n",
    "features['SaleType'] = features['SaleType'].fillna(features['SaleType'].mode()[0])\n",
    "\n",
    "#对于列名为'GarageYrBlt', 'GarageArea', 'GarageCars'的特征列，使用0填充空值。\n",
    "for col in ('GarageYrBlt', 'GarageArea', 'GarageCars'):\n",
    "    features[col] = features[col].fillna(0)\n",
    "\n",
    "#对于列名为'GarageType', 'GarageFinish', 'GarageQual', 'GarageCond'的特征列，使用字符串'None'填充空值。\n",
    "for col in ['GarageType', 'GarageFinish', 'GarageQual', 'GarageCond']:\n",
    "    features[col] = features[col].fillna('None')\n",
    "\n",
    "#对于列名为'BsmtQual', 'BsmtCond', 'BsmtExposure', 'BsmtFinType1', 'BsmtFinType2'的特征列，使用字符串'None'填充空值。\n",
    "for col in ('BsmtQual', 'BsmtCond', 'BsmtExposure', 'BsmtFinType1', 'BsmtFinType2'):\n",
    "    features[col] = features[col].fillna('None')\n",
    "\n",
    "#聚合函数（按某一列关键字分组）groupby，它的特点是：将返回与传入方法的矩阵维度相同的单个序列。\n",
    "#transform是与groupby（pandas中最有用的操作之一）通常组合使用，它对传入方法的矩阵进行维度不变的变换。具体变换方法写在括号中，通常会使用匿名函数，对传入矩阵的所有元素进行操作。\n",
    "#对于features矩阵，按照'MSSubClass'列中的元素分布进行分组，被分组的数据列是'MSZoning'列。feature.groupby(被作为索引的列的名称)[被分组的数据列的名称]\n",
    "#features.groupby('MSSubClass')['MSZoning']后，得到的是一个以'MSSubClass'为索引，以'MSZoning'为数据列的矩阵。\n",
    "#.transform()方法将对'MSZoning'数据列进行()内的变换，它将返回和传入矩阵同样维度的矩阵。\n",
    "#括号内是匿名函数，将对传入矩阵中的空值进行填充，使用的填充元素是传入矩阵中的众数。\n",
    "features['MSZoning'] = features.groupby('MSSubClass')['MSZoning'].transform(lambda x: x.fillna(x.mode()[0]))\n",
    "\n",
    "\n",
    "#判断出features矩阵中列为对象的列，将列名存入objects叔祖。对于features矩阵中的各个列对象，将其列中的空值填充为'None'\n",
    "objects = []\n",
    "for i in features.columns:\n",
    "    if features[i].dtype == object:\n",
    "        objects.append(i)\n",
    "features.update(features[objects].fillna('None'))\n",
    "\n",
    "#使用传入矩阵（'LotFrontage'列）的中位数对传入矩阵中的空值进行填充。\n",
    "#先以'Neighborhood'为标签，以'LotFrontage'为被汇总序列。然后使用被汇总序列中的中位数，对原始矩阵'LotFrontage'列中的空值进行填充。\n",
    "#transform的特性是同维操作，最后输出结果的顺序和原始数据在序号上完全匹配。\n",
    "features['LotFrontage'] = features.groupby('Neighborhood')['LotFrontage'].transform(lambda x: x.fillna(x.median()))\n",
    "\n",
    "\n",
    "#对于整型和浮点型数据列，使用0填充其中的空值。\n",
    "numeric_dtypes = ['int16', 'int32', 'int64', 'float16', 'float32', 'float64']\n",
    "numerics = []\n",
    "for i in features.columns:\n",
    "    if features[i].dtype in numeric_dtypes:\n",
    "        numerics.append(i)\n",
    "features.update(features[numerics].fillna(0))\n",
    "###############################填充空值-【结束】##########################\n",
    "\n",
    "######################数字型数据列偏度校正-【开始】#######################\n",
    "#使用skew()方法，计算所有整型和浮点型数据列中，数据分布的偏度（skewness）。\n",
    "#偏度是统计数据分布偏斜方向和程度的度量，是统计数据分布非对称程度的数字特征。亦称偏态、偏态系数。 \n",
    "numeric_dtypes = ['int16', 'int32', 'int64', 'float16', 'float32', 'float64']\n",
    "numerics2 = []\n",
    "for i in features.columns:\n",
    "    if features[i].dtype in numeric_dtypes:\n",
    "        numerics2.append(i)\n",
    "skew_features = features[numerics2].apply(lambda x: skew(x)).sort_values(ascending=False)\n",
    "\n",
    "#以0.5作为基准，统计偏度超过此数值的高偏度分布数据列，获取这些数据列的index。\n",
    "high_skew = skew_features[skew_features > 0.5]\n",
    "skew_index = high_skew.index\n",
    "\n",
    "#对高偏度数据进行处理，将其转化为正态分布。\n",
    "#Box和Cox提出的变换可以使线性回归模型满足线性性、独立性、方差齐次以及正态性的同时，又不丢失信息。\n",
    "for i in skew_index:\n",
    "    features[i] = boxcox1p(features[i], boxcox_normmax(features[i] + 1))#这是boxcox1p的使用方法，参数的具体意义暂时不解释\n",
    "######################数字型数据列偏度校正-【结束】#######################\n",
    "\n",
    "######################特征删除和融合创建新特征-【开始】###################\n",
    "#删除一些特征。df.drop（‘列名’, axis=1）代表将‘列名’对应的列标签（们）沿着水平的方向依次删掉。\n",
    "features = features.drop(['Utilities', 'Street', 'PoolQC',], axis=1)\n",
    "\n",
    "#融合多个特征，生成新特征。\n",
    "features['YrBltAndRemod']=features['YearBuilt']+features['YearRemodAdd']\n",
    "features['TotalSF']=features['TotalBsmtSF'] + features['1stFlrSF'] + features['2ndFlrSF']\n",
    "\n",
    "features['Total_sqr_footage'] = (features['BsmtFinSF1'] + features['BsmtFinSF2'] +\n",
    "                                 features['1stFlrSF'] + features['2ndFlrSF'])\n",
    "\n",
    "features['Total_Bathrooms'] = (features['FullBath'] + (0.5 * features['HalfBath']) +\n",
    "                               features['BsmtFullBath'] + (0.5 * features['BsmtHalfBath']))\n",
    "\n",
    "features['Total_porch_sf'] = (features['OpenPorchSF'] + features['3SsnPorch'] +\n",
    "                              features['EnclosedPorch'] + features['ScreenPorch'] +\n",
    "                              features['WoodDeckSF'])\n",
    "\n",
    "#简化特征。对于某些分布单调（比如100个数据中有99个的数值是0.9，另1个是0.1）的数字型数据列，进行01取值处理。\n",
    "features['haspool'] = features['PoolArea'].apply(lambda x: 1 if x > 0 else 0)\n",
    "features['has2ndfloor'] = features['2ndFlrSF'].apply(lambda x: 1 if x > 0 else 0)\n",
    "features['hasgarage'] = features['GarageArea'].apply(lambda x: 1 if x > 0 else 0)\n",
    "features['hasbsmt'] = features['TotalBsmtSF'].apply(lambda x: 1 if x > 0 else 0)\n",
    "features['hasfireplace'] = features['Fireplaces'].apply(lambda x: 1 if x > 0 else 0)\n",
    "\n",
    "#检查特征处理后，特征矩阵的维数，核查特征处理结果。\n",
    "print(\"删除了3个特征，又融合创建了10个新特征，处理之后的特征矩阵维度为:\",features.shape)\n",
    "######################特征删除和融合创建新特征-【结束】###################\n",
    "\n",
    "####################特征投影、特征矩阵拆解和截取-【开始】#################\n",
    "#使用.get_dummies()方法对特征矩阵进行类似“坐标投影”操作。获得在新空间下的特征表达。\n",
    "final_features = pd.get_dummies(features).reset_index(drop=True)\n",
    "#打印新空间下的特征维数，也是新空间的维数。\n",
    "print(\"使用get_dummies()方法“投影”特征矩阵，即分解出更多特征，得到更多列。投影后的特征矩阵维度为:\",final_features.shape)\n",
    "\n",
    "#进行特征空间降阶。截取前len(y)行，存入X阵（因为之前进行了训练数据和测试数据的合并，所以从合并矩阵中取出前len(y)行，就得到了训练数据集的处理后的特征矩阵）。\n",
    "#截取剩余部分，即从序号为len(y)的行开始，至矩阵结尾的各行，存入X_sub阵。此为完成特征变换后的测试集特征矩阵。\n",
    "#注：len(df)是行计数方法\n",
    "X = final_features.iloc[:len(y), :]\t#y是列向量，存储了训练数据中的房价列信息。截取后得到的X阵的维度是len(y)*(final_features的列数)。\n",
    "X_sub = final_features.iloc[len(y):, :]#使用len命令，求矩阵X的长度，得到的是矩阵对象的长度，即有矩阵中有多少列，而不是每列上有多少行。\n",
    "print(\"删除了3个特征，又融合创建了10个新特征，处理之后的特征矩阵维度为:\",'X', X.shape, 'y', y.shape, 'X_sub', X_sub.shape)\n",
    "\n",
    "#在新生特征空间中，剔除X阵和y阵中有着极端值的各行数据（因为X和y阵在水平方向上是一致的，所以要一起删除同样的行）。outliers数值中给出了极端值的列序号。\n",
    "#df.drop(df.index[序号])将删除指定序号的各行。再使用=对df覆值。\n",
    "outliers = [30, 88, 462, 631, 1322]\n",
    "X = X.drop(X.index[outliers])#因为X阵是经过对特征矩阵进行类似“坐标投影”操作后得到的，列向量y中的行号对应着X阵中的列号。\n",
    "y = y.drop(y.index[outliers])\n",
    "####################特征投影、特征矩阵拆解和截取-【结束】#################\n",
    "\n",
    "######################消除截取后特征矩阵的过拟合-【开始】#######################  这一步的目的是处理X阵和X_sub阵。\n",
    "#在新生特征空间中，删除将产生过拟合的数据列。\n",
    "\n",
    "#这种数据列具有如下特征：\n",
    "overfit = []#用来记录产生过拟合的数据列的序号\n",
    "for i in X.columns:#遍历截取后特征矩阵的每一列\n",
    "    counts = X[i].value_counts()#使用.value_counts()方法，查看在X矩阵的第i列中，不同的取值分别出现了多少次，默认按次数最高到最低做降序排列。返回一个df。\n",
    "    zeros = counts.iloc[0]#通过行号索引行数据，取出counts列中第一个元素，即出现次数最多的取值到底是出现了多少次，存入zeros\n",
    "    if zeros / len(X) * 100 > 99.94:\n",
    "#判断某一列是否将产生过拟合的条件：\n",
    "#截取后的特征矩阵有len(X)列，如果某一列中的某个值出现的次数除以特征矩阵的列数超过99.94%，即其几乎在被投影的各个维度上都有着同样的取值，并不具有“主成分”的性质，则记为过拟合列。\n",
    "        overfit.append(i)\n",
    "\n",
    "#找到将产生过拟合的数据列的位置后，在特征矩阵中进行删除操作。\n",
    "overfit = list(overfit)\n",
    "#overfit.append('MSZoning_C (all)')#这条语句有用吗？是要把训练数据特征矩阵X中的列标签为'MSZoning_C (all)'的列也删除吗？但是训练数据中并没有任何一个列标签名称为MSZoning_C (all)。\n",
    "X = X.drop(overfit, axis=1)#.copy()#删除截取后特征矩阵X中的过拟合列。因为drop并不影响原数据，所以使用copy。直接覆值应该也可以。\n",
    "X_sub = X_sub.drop(overfit, axis=1)#.copy()\n",
    "######################消除截取后特征矩阵的过拟合-【结束】#######################\n",
    "\n",
    "print(\"删除极端值及过拟合列后，训练数据特征矩阵的维数为，特征：\",'X', X.shape, '对应于特征的对数变换后的房价y', y.shape, '测试数据的特征矩阵（它应该在行、列上未被删减）X_sub', X_sub.shape)\n",
    "##############################################################特征处理-【结束】###################################################################################\n",
    "\n",
    "##############################################################机器学习-【开始】###################################################################################\n",
    "print('特征处理已经完成。开始对训练数据进行机器学习', datetime.now())\n",
    "\n",
    "#设置k折交叉验证的参数。\n",
    "kfolds = KFold(n_splits=10, shuffle=True, random_state=42)\n",
    "\n",
    "\n",
    "#定义均方根对数误差（Root Mean Squared Logarithmic Error ，RMSLE）\n",
    "def rmsle(y, y_pred):\n",
    "    return np.sqrt(mean_squared_error(y, y_pred))\n",
    "\n",
    "\n",
    "#创建模型评分函数，根据不同模型的表现打分\n",
    "#cv表示Cross-validation,交叉验证的意思。\n",
    "def cv_rmse(model, X=X):\n",
    "    rmse = np.sqrt(-cross_val_score(model, X, y, scoring=\"neg_mean_squared_error\", cv=kfolds))\n",
    "    return (rmse)\n",
    "\n",
    "#############个体机器学习模型的创建（即模型声明和参数设置）-【开始】############\n",
    "alphas_alt = [14.5, 14.6, 14.7, 14.8, 14.9, 15, 15.1, 15.2, 15.3, 15.4, 15.5]\n",
    "alphas2 = [5e-05, 0.0001, 0.0002, 0.0003, 0.0004, 0.0005, 0.0006, 0.0007, 0.0008]\n",
    "e_alphas = [0.0001, 0.0002, 0.0003, 0.0004, 0.0005, 0.0006, 0.0007]\n",
    "e_l1ratio = [0.8, 0.85, 0.9, 0.95, 0.99, 1]\n",
    "\n",
    "#定义ridge岭回归模型（使用二范数作为正则化项。不论是使用一范数还是二范数，正则化项的引入均是为了降低过拟合风险。）\n",
    "#注：正则化项如果使用二范数，那么对于任何需要寻优的参数值，在寻优终止时，它都无法将某些参数值变为严格的0，尽管某些参数估计值变得非常小以至于可以忽略。即使用二范数会保留变量的所有信息，不会进行类似PCA的变量凸显。\n",
    "#注：正则化项如果使用一范数，它比L2范数更易于获得“稀疏(sparse)”解，即它的求解结果会有更多的零分量。\n",
    "ridge = make_pipeline(RobustScaler(), RidgeCV(alphas=alphas_alt, cv=kfolds))\n",
    "\n",
    "#定义LASSO收缩模型（使用L1范数作为正则化项）（由于对目标函数的求解结果中将得到很多的零分量，它也被称为收缩模型。）\n",
    "#注：正则化项如果使用二范数，那么对于任何需要寻优的参数值，在寻优终止时，它都无法将某些参数值变为严格的0，尽管某些参数估计值变得非常小以至于可以忽略。即使用二范数会保留变量的所有信息，不会进行类似PCA的变量凸显。\n",
    "#注：正则化项如果使用一范数，它比L2范数更易于获得“稀疏(sparse)”解，即它的求解结果会有更多的零分量。\t\t\t\t\t\t\t\t\t\t\n",
    "lasso = make_pipeline(RobustScaler(), LassoCV(max_iter=1e7, alphas=alphas2, random_state=42, cv=kfolds))\n",
    "\n",
    "#定义elastic net弹性网络模型（弹性网络实际上是结合了岭回归和lasso的特点，同时使用了L1和L2作为正则化项。）\t\t\t\t\t\t\t\t\t\n",
    "elasticnet = make_pipeline(RobustScaler(), ElasticNetCV(max_iter=1e7, alphas=e_alphas, cv=kfolds, l1_ratio=e_l1ratio))\n",
    "\n",
    "#定义SVM支持向量机模型                                     \n",
    "svr = make_pipeline(RobustScaler(), SVR(C= 20, epsilon= 0.008, gamma=0.0003,))\n",
    "\n",
    "#定义GB梯度提升模型（展开到一阶导数）\t\t\t\t\t\t\t\t\t\n",
    "gbr = GradientBoostingRegressor(n_estimators=3000, learning_rate=0.05, max_depth=4, max_features='sqrt', min_samples_leaf=15, min_samples_split=10, loss='huber', random_state =42)                             \n",
    "\n",
    "#定义lightgbm模型\t\t\t\t\t\t\t\t\t\n",
    "lightgbm = LGBMRegressor(objective='regression', \n",
    "                                       num_leaves=4,\n",
    "                                       learning_rate=0.01, \n",
    "                                       n_estimators=5000,\n",
    "                                       max_bin=200, \n",
    "                                       bagging_fraction=0.75,\n",
    "                                       bagging_freq=5, \n",
    "                                       bagging_seed=7,\n",
    "                                       feature_fraction=0.2,\n",
    "                                       feature_fraction_seed=7,\n",
    "                                       verbose=-1,\n",
    "                                       #min_data_in_leaf=2,\n",
    "                                       #min_sum_hessian_in_leaf=11\n",
    "                                       )\n",
    "\n",
    "#定义xgboost模型（展开到二阶导数）                                      \n",
    "xgboost = XGBRegressor(learning_rate=0.01, n_estimators=3460,\n",
    "                                     max_depth=3, min_child_weight=0,\n",
    "                                     gamma=0, subsample=0.7,\n",
    "                                     colsample_bytree=0.7,\n",
    "                                     objective='reg:linear', nthread=-1,\n",
    "                                     scale_pos_weight=1, seed=27,\n",
    "                                     reg_alpha=0.00006)\n",
    "#############个体机器学习模型的创建（即模型声明和参数设置）-【结束】############\n",
    "\n",
    "###########################集成多个个体学习器-【开始】##########################\n",
    "###！！！！！！！！！！！！\n",
    "###！！！！！！！！！！！！\n",
    "###！！！regressors=(...)中并没有纳入前面的svr模型,怎么回事？\n",
    "###！！！！！！！！！！！！\n",
    "###！！！！！！！！！！！！\n",
    "stack_gen = StackingCVRegressor(regressors=(ridge, lasso, elasticnet, gbr, xgboost, lightgbm),\n",
    "                                meta_regressor=xgboost,\n",
    "                                use_features_in_secondary=True)#regressors=(...)中并没有纳入前面的svr模型\n",
    "###########################集成多个个体学习器-【结束】##########################                             \n",
    "\n",
    "############################进行交叉验证打分-【开始】###########################\n",
    "#进行交叉验证，并对不同模型的表现打分\n",
    "#（由于是交叉验证，将使用不同的数据集对同一模型进行评分，故每个模型对应一个得分序列。展示模型得分序列的平均分、标准差）\n",
    "print('进行交叉验证，计算不同模型的得分TEST score on CV')\n",
    "\n",
    "#打印二范数rideg岭回归模型的得分\n",
    "score = cv_rmse(ridge)\n",
    "print(\"二范数rideg岭回归模型的得分: {:.4f} ({:.4f})\\n\".format(score.mean(), score.std()), datetime.now(), )\n",
    "\n",
    "#打印一范数LASSO收缩模型的得分\n",
    "score = cv_rmse(lasso)\n",
    "print(\"一范数LASSO收缩模型的得分: {:.4f} ({:.4f})\\n\".format(score.mean(), score.std()), datetime.now(), )\n",
    "\n",
    "#打印elastic net弹性网络模型的得分\n",
    "score = cv_rmse(elasticnet)\n",
    "print(\"elastic net弹性网络模型的得分: {:.4f} ({:.4f})\\n\".format(score.mean(), score.std()), datetime.now(), )\n",
    "\n",
    "#打印SVR支持向量机模型的得分\n",
    "score = cv_rmse(svr)\n",
    "print(\"SVR支持向量机模型的得分: {:.4f} ({:.4f})\\n\".format(score.mean(), score.std()), datetime.now(), )\n",
    "\n",
    "#打印lightgbm轻梯度提升模型的得分\n",
    "score = cv_rmse(lightgbm)\n",
    "print(\"lightgbm轻梯度提升模型的得分: {:.4f} ({:.4f})\\n\".format(score.mean(), score.std()), datetime.now(), )\n",
    "\n",
    "#打印gbr梯度提升回归模型的得分\n",
    "score = cv_rmse(gbr)\n",
    "print(\"gbr梯度提升回归模型的得分: {:.4f} ({:.4f})\\n\".format(score.mean(), score.std()), datetime.now(), )\n",
    "\n",
    "#打印xgboost模型的得分\n",
    "score = cv_rmse(xgboost)\n",
    "print(\"xgboost模型的得分: {:.4f} ({:.4f})\\n\".format(score.mean(), score.std()), datetime.now(), )\n",
    "############################进行交叉验证打分-【结束】###########################\n",
    "\n",
    "#########使用训练数据特征矩阵作为输入，训练数据对数处理后的预测房价作为输出，进行各个模型的训练-【开始】#########\n",
    "#开始集合所有模型，使用stacking方法\n",
    "print('进行模型参数训练 START Fit')\n",
    "\n",
    "print(datetime.now(), '对stack_gen集成器模型进行参数训练')\n",
    "stack_gen_model = stack_gen.fit(np.array(X), np.array(y))\n",
    "\n",
    "print(datetime.now(), '对elasticnet弹性网络模型进行参数训练')\n",
    "elastic_model_full_data = elasticnet.fit(X, y)\n",
    "\n",
    "print(datetime.now(), '对一范数lasso收缩模型进行参数训练')\n",
    "lasso_model_full_data = lasso.fit(X, y)\n",
    "\n",
    "print(datetime.now(), '对二范数ridge岭回归模型进行参数训练')\n",
    "ridge_model_full_data = ridge.fit(X, y)\n",
    "\n",
    "print(datetime.now(), '对svr支持向量机模型进行参数训练')\n",
    "svr_model_full_data = svr.fit(X, y)\n",
    "\n",
    "print(datetime.now(), '对GradientBoosting梯度提升模型进行参数训练')\n",
    "gbr_model_full_data = gbr.fit(X, y)\n",
    "\n",
    "print(datetime.now(), '对xgboost二阶梯度提升模型进行参数训练')\n",
    "xgb_model_full_data = xgboost.fit(X, y)\n",
    "\n",
    "print(datetime.now(), '对lightgbm轻梯度提升模型进行参数训练')\n",
    "lgb_model_full_data = lightgbm.fit(X, y)\n",
    "#########使用训练数据特征矩阵作为输入，训练数据对数处理后的预测房价作为输出，进行各个模型的训练-【结束】#########\n",
    "\n",
    "############################进行交叉验证打分-【结束】###########################\n",
    "\n",
    "########定义个体学习器的预测值融合函数，检测预测值融合策略的效果-【开始】#######\n",
    "#综合多个模型产生的预测值，作为多模型组合学习器的预测值\n",
    "def blend_models_predict(X):\n",
    "    return ((0.1 * elastic_model_full_data.predict(X)) + \\\n",
    "            (0.05 * lasso_model_full_data.predict(X)) + \\\n",
    "            (0.1 * ridge_model_full_data.predict(X)) + \\\n",
    "            (0.1 * svr_model_full_data.predict(X)) + \\\n",
    "            (0.1 * gbr_model_full_data.predict(X)) + \\\n",
    "            (0.15 * xgb_model_full_data.predict(X)) + \\\n",
    "            (0.1 * lgb_model_full_data.predict(X)) + \\\n",
    "            (0.3 * stack_gen_model.predict(np.array(X))))\n",
    "\n",
    "#打印在上述模型配比下，多模型组合学习器的均方根对数误差（Root Mean Squared Logarithmic Error ，RMSLE）\n",
    "#使用训练数据对创造的模型进行k折交叉验证，以训练创造出的模型的参数配置。交叉验证训练过程结束后，将得到模型的参数配置。使用得出的参数配置下，在全体训练数据上进行验证，验证模型对全体训练数据重构的误差。\n",
    "print('融合后的训练模型对原数据重构时的均方根对数误差RMSLE score on train data:')\n",
    "print(rmsle(y, blend_models_predict(X)))\n",
    "########定义个体学习器的预测值融合函数，检测预测值融合策略的效果-【结束】#######\n",
    "\n",
    "########将测试集的特征矩阵作为输入，传入训练好的模型，得出的输出写入.csv文件的第2列-【开始】########\n",
    "print('使用测试集特征进行房价预测 Predict submission', datetime.now(),)\n",
    "submission = pd.read_csv(\"sample_submission.csv\")\n",
    "#函数注释：.iloc[:,1]是基于索引位来选取数据集，[索引1:索引2]，左闭右开。\n",
    "submission.iloc[:,1] = np.floor(np.expm1(blend_models_predict(X_sub)))\n",
    "########将测试集的特征矩阵作为输入，传入训练好的模型，得出的输出写入.csv文件的第2列-【结束】########\n",
    "\n",
    "#---------------------------------------------------------------------------------------------------------------------------#\n",
    "#---------------------------------------------------------------------------------------------------------------------------#\n",
    "#---------------------------------------------------------------------------------------------------------------------------#\n",
    "\n",
    "# 当对平台未公开的测试集进行预测时，前述模型的误差是0.114 this kernel gave a score 0.114\n",
    "# 为了提高模型的得分，引入其他模型的优秀预测结果，与前述模型的预测结果进行混合（有点类似抄别人的答案，但实质是扩大集成模型的规模，引入更多的模型） let's up it by mixing with the top kernels\n",
    "\n",
    "######################模型输出结果融合-【开始】#############################\n",
    "#在多模型集成学习器预测结果的基础上，融合其他优秀模型（即平台上其他均方根对数误差小的模型）的预测结果。\n",
    "#这步操作是为了降低多模型集成学习器的方差。\n",
    "print('融合其他优秀模型的预测结果 Blend with Top Kernals submissions', datetime.now(),)\n",
    "sub_1 = pd.read_csv('House_Prices_submit.csv')\n",
    "sub_2 = pd.read_csv('hybrid_solution.csv')\n",
    "sub_3 = pd.read_csv('lasso_sol22_Median.csv')\n",
    "submission.iloc[:,1] = np.floor((0.25 * np.floor(np.expm1(blend_models_predict(X_sub)))) + \n",
    "                                (0.25 * sub_1.iloc[:,1]) + \n",
    "                                (0.25 * sub_2.iloc[:,1]) + \n",
    "                                (0.25 * sub_3.iloc[:,1]))\n",
    "######################模型输出结果融合-【结束】#############################      \n",
    "\n",
    "####################融合结果的极端值剔除-【开始】###########################  \n",
    "#处理融合后结果中的极端值。把太大的数值（降序排列时，位于顶部往下0.005的数值，就是只有0.005的数比它大）缩小一点（乘以0.77），把太小的数值（降序排列时，位于顶部往下0.99的数值）放大一点（乘以1.1）\n",
    "q1 = submission['SalePrice'].quantile(0.005)\n",
    "q2 = submission['SalePrice'].quantile(0.995)\n",
    "submission['SalePrice'] = submission['SalePrice'].apply(lambda x: x if x > q1 else x*0.77)\n",
    "submission['SalePrice'] = submission['SalePrice'].apply(lambda x: x if x < q2 else x*1.1)\n",
    "####################融合结果的极端值剔除-【结束】###########################\n",
    "\n",
    "#以csv文件的形式输出预测值\n",
    "submission.to_csv(\"House_price_submission.csv\", index=False)\n",
    "print('融合结果.csv文件输出成功 Save submission', datetime.now())\n",
    "##############################################################机器学习-【结束】###################################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>LotFrontage</th>\n",
       "      <th>LotArea</th>\n",
       "      <th>OverallQual</th>\n",
       "      <th>OverallCond</th>\n",
       "      <th>YearBuilt</th>\n",
       "      <th>YearRemodAdd</th>\n",
       "      <th>MasVnrArea</th>\n",
       "      <th>BsmtFinSF1</th>\n",
       "      <th>BsmtFinSF2</th>\n",
       "      <th>BsmtUnfSF</th>\n",
       "      <th>...</th>\n",
       "      <th>SaleType_ConLw</th>\n",
       "      <th>SaleType_New</th>\n",
       "      <th>SaleType_Oth</th>\n",
       "      <th>SaleType_WD</th>\n",
       "      <th>SaleCondition_Abnorml</th>\n",
       "      <th>SaleCondition_AdjLand</th>\n",
       "      <th>SaleCondition_Alloca</th>\n",
       "      <th>SaleCondition_Family</th>\n",
       "      <th>SaleCondition_Normal</th>\n",
       "      <th>SaleCondition_Partial</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>18.144572</td>\n",
       "      <td>13.833055</td>\n",
       "      <td>7</td>\n",
       "      <td>3.991517</td>\n",
       "      <td>2003</td>\n",
       "      <td>2003</td>\n",
       "      <td>19.433174</td>\n",
       "      <td>144.117862</td>\n",
       "      <td>0.0</td>\n",
       "      <td>29.991052</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20.673625</td>\n",
       "      <td>14.117918</td>\n",
       "      <td>6</td>\n",
       "      <td>6.000033</td>\n",
       "      <td>1976</td>\n",
       "      <td>1976</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>181.719186</td>\n",
       "      <td>0.0</td>\n",
       "      <td>44.135410</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>18.668046</td>\n",
       "      <td>14.476513</td>\n",
       "      <td>7</td>\n",
       "      <td>3.991517</td>\n",
       "      <td>2001</td>\n",
       "      <td>2002</td>\n",
       "      <td>17.768840</td>\n",
       "      <td>110.441033</td>\n",
       "      <td>0.0</td>\n",
       "      <td>56.896528</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>17.249650</td>\n",
       "      <td>14.106197</td>\n",
       "      <td>7</td>\n",
       "      <td>3.991517</td>\n",
       "      <td>1915</td>\n",
       "      <td>1970</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>61.795315</td>\n",
       "      <td>0.0</td>\n",
       "      <td>64.808848</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>21.314282</td>\n",
       "      <td>15.022009</td>\n",
       "      <td>8</td>\n",
       "      <td>3.991517</td>\n",
       "      <td>2000</td>\n",
       "      <td>2000</td>\n",
       "      <td>25.404163</td>\n",
       "      <td>136.624601</td>\n",
       "      <td>0.0</td>\n",
       "      <td>61.166371</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 332 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   LotFrontage    LotArea  OverallQual  OverallCond  YearBuilt  YearRemodAdd  \\\n",
       "0    18.144572  13.833055            7     3.991517       2003          2003   \n",
       "1    20.673625  14.117918            6     6.000033       1976          1976   \n",
       "2    18.668046  14.476513            7     3.991517       2001          2002   \n",
       "3    17.249650  14.106197            7     3.991517       1915          1970   \n",
       "4    21.314282  15.022009            8     3.991517       2000          2000   \n",
       "\n",
       "   MasVnrArea  BsmtFinSF1  BsmtFinSF2  BsmtUnfSF          ...            \\\n",
       "0   19.433174  144.117862         0.0  29.991052          ...             \n",
       "1    0.000000  181.719186         0.0  44.135410          ...             \n",
       "2   17.768840  110.441033         0.0  56.896528          ...             \n",
       "3    0.000000   61.795315         0.0  64.808848          ...             \n",
       "4   25.404163  136.624601         0.0  61.166371          ...             \n",
       "\n",
       "   SaleType_ConLw  SaleType_New  SaleType_Oth  SaleType_WD  \\\n",
       "0               0             0             0            1   \n",
       "1               0             0             0            1   \n",
       "2               0             0             0            1   \n",
       "3               0             0             0            1   \n",
       "4               0             0             0            1   \n",
       "\n",
       "   SaleCondition_Abnorml  SaleCondition_AdjLand  SaleCondition_Alloca  \\\n",
       "0                      0                      0                     0   \n",
       "1                      0                      0                     0   \n",
       "2                      0                      0                     0   \n",
       "3                      1                      0                     0   \n",
       "4                      0                      0                     0   \n",
       "\n",
       "   SaleCondition_Family  SaleCondition_Normal  SaleCondition_Partial  \n",
       "0                     0                     1                      0  \n",
       "1                     0                     1                      0  \n",
       "2                     0                     1                      0  \n",
       "3                     0                     0                      0  \n",
       "4                     0                     1                      0  \n",
       "\n",
       "[5 rows x 332 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 1453 entries, 0 to 1457\n",
      "Columns: 332 entries, LotFrontage to SaleCondition_Partial\n",
      "dtypes: float64(32), int64(11), uint8(289)\n",
      "memory usage: 909.5 KB\n"
     ]
    }
   ],
   "source": [
    "X.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
